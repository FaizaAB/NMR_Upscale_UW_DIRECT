{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d033b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381ecbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_600=pd.DataFrame()\n",
    "df_600=pd.read_csv(\"600.csv\")\n",
    "df_fake=pd.DataFrame()\n",
    "df_fake=pd.read_csv(\"fake_data.csv\")\n",
    "df_60=pd.DataFrame()\n",
    "df_60=pd.read_csv(\"60.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ae9295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_60, df_600, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train.values).float()\n",
    "y_train = torch.tensor(y_train.values).float()\n",
    "x_val = torch.tensor(x_val.values).float()\n",
    "y_val = torch.tensor(y_val.values).float()\n",
    "x_test = torch.tensor(x_test.values).float()\n",
    "y_test = torch.tensor(y_test.values).float()\n",
    "fake_data=torch.tensor(df_fake.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ad82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f13ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(5500, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 4096)\n",
    "        self.fc6 = nn.Linear(4096, 8192)\n",
    "        self.fc7 = nn.Linear(8192, 16384)\n",
    "        self.fc8 = nn.Linear(16384, 30720)\n",
    "        self.fc9 = nn.Linear(30720, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = nn.functional.relu(self.fc5(x))\n",
    "        x = nn.functional.relu(self.fc6(x))\n",
    "        x = nn.functional.relu(self.fc7(x))\n",
    "        x = nn.functional.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d144f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29e52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(5500, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 2048)\n",
    "        self.fc5 = nn.Linear(2048, 4096)\n",
    "        self.fc6 = nn.Linear(4096, 8192)\n",
    "        self.fc7 = nn.Linear(8192, 16384)\n",
    "        self.fc8 = nn.Linear(16384, 30720)\n",
    "        self.fc9 = nn.Linear(30720, 5500)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = nn.functional.relu(self.fc5(x))\n",
    "        x = nn.functional.relu(self.fc6(x))\n",
    "        x = nn.functional.relu(self.fc7(x))\n",
    "        x = nn.functional.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd51343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe1a776",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# GAN model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGAN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,discriminator_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, generator_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(GAN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 94\u001b[0m, in \u001b[0;36mGAN\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         train_generator(\u001b[38;5;28mself\u001b[39m,train_x)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     train_discriminator(y_train,data_f)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m'''def generate(self, num_samples):\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    noise = torch.randn(num_samples, self.input_size)\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    return self.generator(noise)'''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m, in \u001b[0;36mGAN.train_model\u001b[0;34m(train_X, train_Y)\u001b[0m\n\u001b[1;32m     79\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     80\u001b[0m optimizer_model\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 82\u001b[0m \u001b[43mtrain_generator\u001b[49m(\u001b[38;5;28mself\u001b[39m,train_x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# GAN model\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self,discriminator_lr=0.001, generator_lr=0.001):\n",
    "        super(GAN, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.d_optimizer = optim.Adam(discriminator.parameters(), lr=discriminator_lr)\n",
    "        self.g_optimizer = optim.Adam(generator.parameters(), lr=generator_lr)\n",
    "        self.loss = nn.BCELoss()\n",
    "        \n",
    "    def train_discriminator(self, train_y,data_f):\n",
    "        self.d_optimizer.zero_grad()\n",
    "        real_labels = torch.ones(real_data.size(0), 1)\n",
    "        fake_labels = torch.zeros(real_data.size(0), 1)\n",
    "\n",
    "        # Train discriminator on real data\n",
    "        real_output = self.discriminator(real_data)\n",
    "        real_loss = self.loss(real_output, real_labels)\n",
    "\n",
    "        # Train discriminator on fake data generated by generator\n",
    "        noise = data_f\n",
    "        fake_data = noise #self.generator(noise)\n",
    "        fake_output = self.discriminator(fake_data)\n",
    "        fake_loss = self.loss(fake_output, fake_labels)\n",
    "\n",
    "        # Compute total discriminator loss and backpropagate\n",
    "        total_loss = real_loss + fake_loss\n",
    "        total_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "\n",
    "        \n",
    "    def train_generator(self,data_f):\n",
    "        self.g_optimizer.zero_grad()\n",
    "        #labels = torch.ones(real_data.size(0), 1)\n",
    "\n",
    "        # Generate fake data and compute generator loss\n",
    "        #noise = data_f\n",
    "        #fake_data = self.generator(noise)\n",
    "        output = self.discriminator(data_f)\n",
    "        loss = self.loss(output, labels)\n",
    "\n",
    "        # Backpropagate and update generator weights\n",
    "        loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def train_model(train_X,train_Y):\n",
    "        generator=Generator()\n",
    "        discriminator=Discriminator()\n",
    "        \n",
    "        # Define the loss function and optimizer\n",
    "        criterion_model = nn.MSELoss()\n",
    "        optimizer_model = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        batch_size=500\n",
    "        \n",
    "        for i in range(0, x_train.shape[0], batch_size):\n",
    "            # Get the batch\n",
    "            batch_x = x_train[i:i+batch_size]\n",
    "            batch_y = y_train[i:i+batch_size]\n",
    "        \n",
    "                # Zero the parameter gradients\n",
    "            optimizer_model.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "            outputs = generator(batch_x)\n",
    "\n",
    "                # Compute the loss\n",
    "            loss = criterion_model(outputs, batch_y)\n",
    "\n",
    "                # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer_model.step()\n",
    "                \n",
    "            train_generator(self,train_x)\n",
    "                \n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "        \n",
    "    for epo in range(5):\n",
    "            \n",
    "        train_model(x_train,y_train)\n",
    "        train_discriminator(y_train,data_f)\n",
    "                \n",
    "                \n",
    "\n",
    "    '''def generate(self, num_samples):\n",
    "        noise = torch.randn(num_samples, self.input_size)\n",
    "        return self.generator(noise)'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53021faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee256f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "GAN.train_model() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39mGAN()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfake_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtest(x_test,y_test)\n",
      "Cell \u001b[0;32mIn[27], line 88\u001b[0m, in \u001b[0;36mGAN.train\u001b[0;34m(self, train_x, train_y, data_f, num_epochs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epo)\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     mod\u001b[38;5;241m.\u001b[39mtrain_discriminator(train_y,data_f)\n",
      "\u001b[0;31mTypeError\u001b[0m: GAN.train_model() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model=GAN()\n",
    "model.train(x_train,y_train,fake_data,)\n",
    "model.test(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de449ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test,Y_test):\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs, Y_test)\n",
    "            return test_outputs\n",
    "        print(f\"Test Loss: {test_loss.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
